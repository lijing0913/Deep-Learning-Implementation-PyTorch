{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e1380c5",
   "metadata": {
    "origin_pos": 1
   },
   "source": [
    "# Multiple Input and Multiple Output Channels\n",
    "\n",
    "Each RGB input image has shape $3\\times h\\times w$.\n",
    "We refer to this axis, with a size of 3, as the *channel* dimension. \n",
    "\n",
    "## Multiple Input Channels\n",
    "\n",
    "When the input data contains multiple channels,\n",
    "we need to construct a convolution kernel\n",
    "with the same number of input channels as the input data,\n",
    "so that it can perform cross-correlation with the input data.\n",
    "Assuming that the number of channels for the input data is $c_i$,\n",
    "the number of input channels of the convolution kernel also needs to be $c_i$. If our convolution kernel's window shape is $k_h\\times k_w$,\n",
    "then when $c_i=1$, we can think of our convolution kernel\n",
    "as just a two-dimensional tensor of shape $k_h\\times k_w$.\n",
    "\n",
    "However, when $c_i>1$, we need a kernel\n",
    "that contains a tensor of shape $k_h\\times k_w$ for *every* input channel. Concatenating these $c_i$ tensors together\n",
    "yields a convolution kernel of shape $c_i\\times k_h\\times k_w$.\n",
    "Since the input and convolution kernel each have $c_i$ channels,\n",
    "we can perform a cross-correlation operation\n",
    "on the two-dimensional tensor of the input\n",
    "and the two-dimensional tensor of the convolution kernel\n",
    "for each channel, adding the $c_i$ results together\n",
    "(summing over the channels)\n",
    "to yield a two-dimensional tensor.\n",
    "This is the result of a two-dimensional cross-correlation\n",
    "between a multi-channel input and\n",
    "a multi-input-channel convolution kernel.\n",
    "\n",
    "**Implement cross-correlation operations with multiple input channels**.\n",
    "Notice that all we are doing is performing a cross-correlation operation\n",
    "per channel and then adding up the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68da6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d160cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def corr2d(X, K): # X: input; K: kernel\n",
    "#     \"\"\"Compute 2D cross-correlation\"\"\"\n",
    "#     h, w = K.shape\n",
    "#     Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "#     for i in range(Y.shape[0]):\n",
    "#         for j in range(Y.shape[1]):\n",
    "#             Y[i, j] = (X[i:i + h, j:j + w] * K).sum() # element-wise multiplication\n",
    "#     return Y\n",
    "\n",
    "def corr2d_multi_in(X, K):\n",
    "    # Iterate through the 0th dimension (channel) of K first, then add them up\n",
    "    return sum(d2l.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3604d96",
   "metadata": {},
   "source": [
    "Validate the output of the cross-correlation operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "57e0f448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "               [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef8cf08",
   "metadata": {},
   "source": [
    "## Multiple Output Channels\n",
    "\n",
    "Regardless of the number of input channels,\n",
    "so far we always ended up with one output channel.\n",
    "However, it turns out to be essential to have multiple channels at each layer.\n",
    "\n",
    "Denote by $c_i$ and $c_o$ the number\n",
    "of input and output channels, respectively,\n",
    "and let $k_h$ and $k_w$ be the height and width of the kernel.\n",
    "To get an output with multiple channels,\n",
    "we can create a kernel tensor\n",
    "of shape $c_i\\times k_h\\times k_w$\n",
    "for *every* output channel.\n",
    "We concatenate them on the output channel dimension,\n",
    "so that the shape of the convolution kernel\n",
    "is $c_o\\times c_i\\times k_h\\times k_w$.\n",
    "In cross-correlation operations,\n",
    "the result on each output channel is calculated\n",
    "from the convolution kernel corresponding to that output channel\n",
    "and takes input from all channels in the input tensor.\n",
    "\n",
    "We implement a cross-correlation function\n",
    "to **calculate the output of multiple channels** as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ebf1b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of `K`, and each time, perform\n",
    "    # cross-correlation operations with input `X`. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)\n",
    "\n",
    "# We construct a trivial convolution kernel with 3 output channels\n",
    "# by concatenating the kernel tensor for `K` with `K+1` and `K+2`.\n",
    "K = torch.stack((K, K + 1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490f563b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b943fef3",
   "metadata": {},
   "source": [
    "## $1\\times 1$ Convolutional Layer\n",
    "\n",
    "At first, a **$1 \\times 1$ convolution**, i.e., $k_h = k_w = 1$,\n",
    "does not seem to make much sense.\n",
    "After all, a convolution correlates adjacent pixels.\n",
    "A $1 \\times 1$ convolution obviously does not.\n",
    "Because the minimum window is used,\n",
    "the $1\\times 1$ convolution loses the ability\n",
    "of larger convolutional layers\n",
    "to recognize patterns consisting of interactions\n",
    "among adjacent elements in the height and width dimensions.\n",
    "The only computation of the $1\\times 1$ convolution occurs\n",
    "on the channel dimension.\n",
    "\n",
    "You could think of the $1\\times 1$ convolutional layer\n",
    "as constituting a fully connected layer applied at every single pixel location\n",
    "to transform the $c_i$ corresponding input values into $c_o$ output values.\n",
    "Because this is still a convolutional layer,\n",
    "the weights are tied across pixel location.\n",
    "Thus the $1\\times 1$ convolutional layer requires $c_o\\times c_i$ weights\n",
    "(plus the bias). Also note that convolutional layers are typically followed \n",
    "by nonlinearities. This ensures that $1 \\times 1$ convolutions cannot simply be \n",
    "folded into other convolutions. \n",
    "\n",
    "We implement a $1 \\times 1$ convolution\n",
    "using a fully connected layer.\n",
    "The only thing is that we need to make some adjustments\n",
    "to the data shape before and after the matrix multiplication.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4e35f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_0 = K.shape[0] # the number of kernel = the number of output channels\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # Matrix multiplication in the fully connected layer\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))\n",
    "\n",
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
